# 项目难点？

优化和思考？

> 如果每个用户都从数据库中获取文章资源，那么MySQL的负载就会很大，那么如何降低MySQL的负载呢？

对象存储服务（Object Storage Service，OSS）`minIO` 存储项目的静态资源，在数据库中存储url。每次访问资源时，根据文章id获取文章的url，使用url直接访问`minIO`，获取静态资源，然后将热点文章的url存储在redis中，不用每次都去到数据库中取出文章信息，提高加载速率并且降低MySQL的访问量。更新文章也是通过修改`minIO`上的文件资源来实现的。

会为每个行为如点赞、收藏和浏览赋予不同的权重，redis 用做缓存，用ZSet存储每个文章近期的点赞数和浏览量的热点值，用消息队列异步更新mysql数据，xxl-job定时任务去计算更新热点文章。



# 数据库

## 数据库索引

数据库索引是一种用于加速查询操作的数据结构。它通过按照特定列的值进行排序和组织数据，以实现更快速的数据检索。在数据库设计中，应该在经常被查询的列上创建索引，以提高查询性能。例如，在一个电子商务网站的商品表中，我们可以在商品名称和商品类别等常用查询条件的列上创建索引，以加速根据商品名称或类别进行搜索的操作。然而，过多的索引可能会增加写操作的开销，并占用额外的存储空间。因此，在创建索引时需要权衡索引的数量和性能影响。

## 索引类型


在 MySQL 中，主要有以下几种类型的索引：

1. **B树索引**（B-tree Index）：
   - B树索引是最常见的索引类型，适用于等值查询和范围查询。
   - B树索引适用于普通查询和排序查询，可以在 MySQL 中的普通表和唯一约束索引上创建。
2. **哈希索引**（Hash Index）：
   - 哈希索引适用于等值查询，但不适用于范围查询。
   - 哈希索引适用于内存表，不支持唯一约束，也不能在外键上创建。
3. **全文索引**（Full-text Index）：
   - 全文索引适用于对文本字段进行全文搜索的场景，如文章标题、内容等。
   - 全文索引适用于 InnoDB 存储引擎中的 MyISAM 表。
4. **空间索引**（Spatial Index）：
   - 空间索引适用于地理数据和空间数据的查询，如地图坐标点。
   - 空间索引适用于 InnoDB 存储引擎中的 MyISAM 表。
5. **全文空间索引**（Full-text Spatial Index）：
   - 全文空间索引结合了全文索引和空间索引的功能，适用于同时对文本和空间数据进行查询的场景。

## 索引优化

1. **选择合适的索引**：确保表中的列上有适当的索引。索引应该根据查询的频率和性质来选择。通常，通过 `WHERE`、`JOIN` 和 `ORDER BY` 子句中经常使用的列创建索引。
2. **联合索引**：考虑使用联合索引来覆盖多个查询条件。联合索引是针对多个列的索引，可以更好地支持复合查询。
3. **避免使用通配符开头的查询**：对于以通配符开头的查询，如 `LIKE '%value'`，MySQL 无法使用索引来加速查询，因为它需要扫描整个索引。尽量避免在查询中使用通配符开头。
4. **使用索引覆盖查询**：索引覆盖查询是指查询只需要从索引中获取数据而无需访问表本身。这可以减少I/O开销。确保所需的列包含在索引中，这样MySQL就可以直接使用索引而不必去访问表。
5. **监控和调整缓冲池大小**：MySQL 使用缓冲池来存储索引和数据。根据系统的负载和需求，调整缓冲池的大小以最大限度地减少磁盘 I/O。
6. **定期分析性能**：监控数据库的性能，并根据需要调整索引和查询，以确保系统始终保持在最佳状态。

## 隔离级别

* **读未提交（Read UnCommitted/RU）**

  一个事务可以读取到另一个事务未提交的数据。

  **脏读**：如果另一个事务发起了回滚，会导致数据一致性问题。

* **读已提交（Read Committed/RC）**

  一个事务提交之后，它做的变更才会被其它事务看到

  **不可重复读**：同一事务先后读取同一个数据，在这期间数据发送了变化，两次读取的结果不一致。

* **可重复读（Repeatable Read）**（MySQL的InnoDB默认的隔离级别）

  一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。

  **幻读**：同一事务按照某个条件先后两次查询数据库，两次查询结果的条数不同，这种现象称为幻读。不可重复读与幻读的区别可以通俗的理解为前者是数据变了，后者是数据的行数变了。

* **可串行化**

## InnoDB 引擎

**InnoDB的数据文件本身就是主索引文件。而MyISAM的主索引和数据是分开的。**

InnoDB的辅助索引data域存储相应记录主键的值而不是地址

MyISAM使用的是表锁  InnoDB使用行锁

InnoDB支持事务和MVCC

InnoDB如果没有设定主键或非空唯一索引，就会自动生成一个6字节的主键，数据是主索引的一部分，附加索引保存的是主索引的值

## MySQL常用的函数


MySQL 中有许多常用的函数，用于对数据进行处理、计算和操作。以下是一些常见的 MySQL 函数：

1. **字符串函数**：
   - CONCAT()：连接两个或多个字符串。
   - SUBSTRING()：返回字符串的子串。
   - REPLACE()：替换字符串中的子串。
   - LENGTH()：返回字符串的长度。
   - UPPER()、LOWER()：将字符串转换为大写或小写。
   - TRIM()：去除字符串两端的空格。
2. **数值函数**：
   - ABS()：返回一个数的绝对值。
   - ROUND()：四舍五入取整。
   - CEIL()、FLOOR()：向上取整、向下取整。
   - MOD()：返回两个数相除的余数。
   - RAND()：返回一个随机数。
3. **日期和时间函数**：
   - NOW()：返回当前日期和时间。
   - CURDATE()、CURTIME()：返回当前日期或时间。
   - DATE_FORMAT()：格式化日期和时间。
   - DATEDIFF()、TIMEDIFF()：计算日期或时间的差值。
   - DATE_ADD()、DATE_SUB()：日期加减操作。
4. **条件函数**：
   - IF()、CASE WHEN THEN ELSE END：条件判断和分支处理。
5. **聚合函数**：
   - SUM()、AVG()：求和、平均值。
   - COUNT()：计算行数或非空值数量。
   - MAX()、MIN()：求最大值、最小值。
   - GROUP_CONCAT()：将多行数据合并为一个字符串。
6. **信息函数**：
   - VERSION()：返回 MySQL 服务器的版本信息。
   - DATABASE()：返回当前数据库的名称。
   - USER()：返回当前用户的用户名和主机名。

# 操作系统

## 请求分页过程

1. **请求分页（Demand Paging）**：是指操作系统在需要时才将页面加载到内存中，而不是一次性将整个进程加载进内存。当程序需要访问某个页面时，如果该页面不在内存中，操作系统就会将该页面从磁盘读取到内存中。
2. **分页请求过程**：
   - 当程序访问某个页面时，CPU 发出一个访存请求。
   - 操作系统检查请求的页面是否在内存中。
   - 如果在内存中，就将页面映射到CPU地址空间。
   - 如果不在内存中，则发生缺页中断（Page Fault）。
   - 缺页中断处理程序负责从磁盘中加载页面到内存，并更新页表。
   - 最后，重新执行被中断的指令。

## 调度算法

1. **调度算法**：是操作系统用来确定哪个进程将被执行的策略。
2. 常见调度算法
   - **先来先服务（First Come First Serve, FCFS）**：按照进程到达的顺序执行。
   - **短作业优先（Shortest Job First, SJF）**：执行最短的作业或最短执行时间的进程。
   - **优先级调度（Priority Scheduling）**：给每个进程分配一个优先级，优先级高的先执行。
   - **轮转调度（Round Robin Scheduling）**：每个进程被分配一个时间片，在时间片结束后，轮转到下一个进程。

## 内存扩容原理

1. **内存扩容**：是指在系统运行时增加可用的物理内存。

2. 原理

   ：内存扩容可以通过以下步骤实现：

   - **检测当前内存使用情况**：操作系统会监视当前内存的使用情况，包括空闲内存量和进程所需的内存量。
   - **确定扩容策略**：根据当前内存使用情况，决定是否需要扩容以及扩容的规模。
   - **分配新的物理内存**：操作系统会向系统中添加新的物理内存，并更新内存管理数据结构（如页表）以反映新的内存布局。
   - **重新分配进程**：如果需要，操作系统会重新分配进程到新的内存地址空间中。
   - **更新系统状态**：操作系统会更新系统状态以反映内存扩容，确保系统能够正确地使用新的物理内存。

## 进程原理

1. **进程创建**：操作系统可以通过创建新的进程来执行程序。进程创建包括分配内存空间、加载程序代码、初始化数据等步骤。
2. **进程调度**：操作系统根据一定的调度策略来决定哪个进程执行、暂停或等待。常见的调度算法包括先来先服务、短作业优先、优先级调度、轮转调度等。
3. **进程同步**：多个进程之间可能会竞争共享资源，为了避免数据的不一致性和竞态条件，需要使用同步机制。互斥量和信号量就是用来实现进程同步的机制之一。
4. **进程通信**：进程间需要进行数据交换和信息传递，以完成合作任务。除了同步机制外，还可以使用管道、消息队列、共享内存等机制来实现进程通信。

## 互斥量（Mutex）

1. **互斥量原理**：互斥量是一种同步原语，用于确保在任意给定时间内只有一个进程能够访问共享资源。它提供了两种操作：lock（加锁）和unlock（解锁）。
2. **使用场景**：当多个进程或线程需要访问共享资源时，可以使用互斥量来保护临界区，确保只有一个进程能够进入临界区执行操作。

## 信号量机制

1. **信号量原理**：信号量是一种用于进程间同步和互斥的机制，它可以用来控制对共享资源的访问。信号量可以是计数器，用来表示可用资源的数量。
2. **类型**：信号量可以分为二元信号量（二值信号量）和计数信号量。二元信号量只能取两个值，通常用于互斥；而计数信号量可以表示多个资源的数量。
3. **操作**：信号量提供了P操作（等待或减少）和V操作（发信号或增加）两种基本操作。P操作用于申请资源，如果资源不可用，则阻塞进程；V操作用于释放资源，并唤醒可能被阻塞的进程。

## Epoll 模型

1. **边缘触发（Edge-Triggered，ET）**：
   - 边缘触发模式是指当文件描述符的状态发生变化时，只通知一次，直到下一次读取或写入操作完成之前，不再重复通知。
   - 如果文件描述符处于可读或可写状态，epoll_wait() 函数返回，之后即使文件描述符仍处于可读或可写状态，也不会再次通知。
2. **水平触发（Level-Triggered，LT）**：
   - 水平触发模式是指当文件描述符的状态发生变化时，每次调用 epoll_wait() 函数时都会通知，直到文件描述符的状态变为非活跃状态。
   - 即使在读取或写入操作未完成时，文件描述符处于可读或可写状态，也会每次调用 epoll_wait() 函数时都通知。

一般来说，边缘触发模式（ET）会更加高效，因为它只在状态发生变化时通知一次，减少了不必要的通知次数，提高了处理效率。相比之下，水平触发模式（LT）在每次调用 epoll_wait() 函数时都会通知，可能会导致频繁的上下文切换和系统调用，影响性能。

## 死锁

死锁条件：

死锁发生通常需要满足以下四个条件：

1. **互斥条件（Mutual Exclusion）**：
   - 至少有一个资源必须是被排他使用的，即一次只能被一个进程或线程访问。
2. **请求与保持条件（Hold and Wait）**：
   - 进程已经持有至少一个资源，并且在等待获取其他进程持有的资源。
3. **不可剥夺条件（No Preemption）**：
   - 已经分配给进程的资源不能被强制性地剥夺，只能由持有它的进程自愿释放。
4. **循环等待条件（Circular Wait）**：
   - 多个进程形成一个循环等待资源的环路，每个进程都在等待下一个进程所持有的资源。

避免死锁的策略：

1. **破坏互斥条件**：
   - 尽量减少资源的互斥使用，或者使用可共享的资源代替排他资源。
2. **破坏请求与保持条件**：
   - 要求进程在开始执行前一次性获取所有需要的资源，而不是逐个获取。
3. **破坏不可剥夺条件**：
   - 允许操作系统剥夺一部分资源，以满足其他进程的资源请求。
4. **破坏循环等待条件**：
   - 通过对资源进行排序，要求进程按照固定顺序请求资源，从而避免循环等待。
5. **资源分配图**：
   - 使用资源分配图检测死锁，并根据检测结果采取相应的措施。
6. **超时机制**：
   - 对资源的申请设置超时机制，在一定时间内未能获取到资源，则放弃当前申请，释放已占有的资源，以避免死锁的发生。
7. **死锁检测与恢复**：
   - 定期检测系统中是否存在死锁，如果存在则采取相应的恢复措施，如资源剥夺或进程终止等。

## 指令

查看磁盘占用：

1. **df**：显示磁盘空间使用情况。

   ```
   bashCopy code
   df -h
   ```

   `-h` 参数用于以人类可读的方式显示磁盘空间使用情况。

2. **du**：显示目录或文件的磁盘使用情况。

   ```
   bashCopy code
   du -h /path/to/directory
   ```

   `-h` 参数同样用于以人类可读的方式显示。

查看CPU占用：

1. **top**：动态显示系统中各个进程的资源占用情况，包括 CPU 和内存占用。

   ```
   bashCopy code
   top
   ```

   按下 `q` 键退出。

2. **htop**：类似于 top，但提供了更多的交互式功能。

   ```
   bashCopy code
   htop
   ```

   按下 `q` 键退出。

3. **ps**：显示当前正在运行的进程信息。

   ```
   bashCopy code
   ps aux | grep <process_name>
   ```

   可以结合 `grep` 命令查找特定进程。

查看内存占用：

1. **free**：显示系统内存使用情况。

   ```
   bashCopy code
   free -h
   ```

   `-h` 参数用于以人类可读的方式显示内存使用情况。

2. **top** 和 **htop**：在 top 或 htop 中可以看到内存占用情况。

3. **vmstat**：显示系统的虚拟内存、进程、内存、IO 等信息。

   ```
   bashCopy code
   vmstat
   ```

   可以通过查看 `free` 和 `buff` 列来了解内存占用情况。

这些命令可以帮助你实时监视系统的磁盘、CPU 和内存占用情况，从而及时发现和解决系统性能问题。

# 计算机网络

1. 物理层

- 主要负责传输比特流（Bit Stream），定义了物理媒介的传输规范。
- 协议：Ethernet、Wi-Fi、USB等。
- 过程：将比特流转换成电信号或光信号进行传输。

2. 数据链路层

- 提供可靠的数据传输，通过控制物理层的传输错误和数据帧的流量控制。
- 协议：以太网（Ethernet）、PPP（Point-to-Point Protocol）等。
- 过程：将数据分成帧，并添加首部和尾部进行传输。

3. 网络层

- 提供数据包的传输和路由选择。
- 协议：IP（Internet Protocol）、ICMP（Internet Control Message Protocol）等。
- 过程：通过 IP 地址进行数据包的路由选择和传输。

4. 传输层

- 提供端到端的通信和数据传输控制。
- 协议：TCP（Transmission Control Protocol）、UDP（User Datagram Protocol）等。
- 过程：确保数据的可靠传输、流量控制和拥塞控制。

5. 会话层

- 管理和协调不同进程之间的通信和会话。
- 协议：RPC（Remote Procedure Call）、NetBIOS等。
- 过程：建立、管理和终止会话。

6. 表示层

- 数据的格式化和编码，确保不同系统的数据能够正确解释。
- 协议：JPEG、ASCII等。
- 过程：数据的压缩、加密、编码和解码等操作。

7. 应用层

- 提供用户接口和应用程序，实现特定的网络功能和服务。
- 协议：HTTP（HyperText Transfer Protocol）、SMTP（Simple Mail Transfer Protocol）、FTP（File Transfer Protocol）等。
- 过程：向用户提供各种网络服务，如网页浏览、电子邮件传输、文件传输等。

## ARP 协议

ARP（Address Resolution Protocol，地址解析协议）是用于获取目标 IP 地址对应的 MAC 地址的协议。

- ### 过程

  1. 当一台设备需要发送数据到一个 IP 地址时，首先会检查自己的 ARP 缓存表，看目标 IP 地址是否已经映射到了 MAC 地址。如果有，就可以直接发送数据。
  2. 如果目标 IP 地址未在缓存表中找到对应的 MAC 地址，发送设备就会向局域网内广播一个 ARP 请求报文，询问该 IP 地址的 MAC 地址。
  3. 局域网内所有设备都会接收到 ARP 请求报文，但只有目标 IP 地址对应的设备会回复一个 ARP 响应报文，包含自己的 MAC 地址。
  4. 发送设备收到 ARP 响应报文后，会将目标 IP 地址和 MAC 地址的映射关系存储到自己的 ARP 缓存表中，以便将来的使用。
  5. 最后，发送设备就可以使用目标 IP 地址对应的 MAC 地址发送数据了。

ARP 协议通过将 IP 地址转换为 MAC 地址，实现了在网络中不同设备之间的通信。

## WebSocket

- WebSocket本质上一种`计算机网络应用层的协议`
- `WebSocket` 通过握手建立连接，并使用单个 TCP 连接进行全双工通信。
- 它能够保持长连接状态，因为连接建立后不会立即关闭。
- 在握手阶段使用的是 HTTP 协议，但通信数据遵循 `WebSocket` 协议。
- 数据格式比较轻量，性能开销小，通信高效。
- 可以发送文本，也可以发送二进制数据。
- 没有同源限制，客户端可以与任意服务器通信。
- 协议标识符是`ws`（如果加密，则为`wss`），服务器网址就是 URL。



## TCP 流量控制

* ### TCP 流量控制的原理：

1. **滑动窗口机制**：
   - TCP 使用滑动窗口（Sliding Window）来控制发送方发送数据的速率。
   - 接收方会在 TCP 报文中的选项字段中指定一个窗口大小，表示自己的接收缓冲区大小。
2. **窗口调整**：
   - 发送方根据接收方指定的窗口大小来确定可以发送的数据量。
   - 如果接收方的缓冲区还有足够的空间，发送方就可以继续发送数据；如果接收方的缓冲区已满，发送方则需要等待接收方释放空间。
3. **动态调整窗口大小**：
   - TCP 使用滑动窗口机制动态调整窗口大小，以适应网络条件的变化和接收方的处理能力。
   - 如果网络拥塞或接收方处理能力不足，接收方可以通过调整窗口大小来通知发送方减慢发送速率。

## 状态码

1. **1xx 信息响应**：
   - 100 Continue：服务器已接收到请求的头部，并且客户端应继续发送请求的主体部分。
   - 101 Switching Protocols：服务器已经理解了客户端的请求，并将通过 Upgrade 消息头通知客户端更改协议。
2. **2xx 成功**：
   - 200 OK：请求已成功。
   - 201 Created：请求已经被实现，且一个新资源已经依据请求的需要而建立。
   - 204 No Content：服务器成功处理了请求，但没有返回任何内容。
3. **3xx 重定向**：
   - 301 Moved Permanently：请求的资源已被永久移动到新的 URI。
   - 302 Found：请求的资源临时从不同的 URI 响应请求。
   - 304 Not Modified：客户端发送条件请求时，服务器允许访问资源，但未符合条件，不返回内容。
4. **4xx 客户端错误**：
   - 400 Bad Request：服务器无法理解请求的语法。
   - 403 Forbidden：服务器拒绝请求。
   - 404 Not Found：服务器未能找到请求的资源。
5. **5xx 服务器错误**：
   - 500 Internal Server Error：服务器遇到了不知道如何处理的情况。
   - 503 Service Unavailable：服务器暂时无法处理请求，通常是由于维护或过载。

## DNS解析过程

DNS（Domain Name System，域名系统）是一种用于将域名解析为 IP 地址的分布式数据库系统。DNS 域名解析的过程主要分为以下几个步骤：

1. **本地域名解析**：
   - 当用户在浏览器中输入一个域名时，操作系统首先会查询本地 DNS 缓存，看是否有该域名对应的 IP 地址。如果有，直接返回结果；如果没有，则进行下一步操作。
2. **递归解析**：
   - 如果本地 DNS 缓存中没有目标域名的 IP 地址，操作系统会向本地 DNS 服务器发出查询请求。
   - 本地 DNS 服务器首先查询自己的缓存，如果有目标域名的 IP 地址，则返回结果给客户端；如果没有，则进行下一步操作。
3. **根域名服务器查询**：
   - 如果本地 DNS 服务器的缓存中没有目标域名的 IP 地址，它会向根域名服务器发送查询请求。
   - 根域名服务器返回给本地 DNS 服务器一个 TLD（顶级域名）的 IP 地址，如 .com、.net、.org 等。
4. **顶级域名服务器查询**：
   - 本地 DNS 服务器收到根域名服务器返回的 TLD 的 IP 地址后，再向相应的顶级域名服务器发送查询请求。
   - 顶级域名服务器返回给本地 DNS 服务器一个二级域名的 IP 地址，如 example.com。
5. **权威域名服务器查询**：
   - 本地 DNS 服务器收到顶级域名服务器返回的二级域名的 IP 地址后，再向对应的权威域名服务器发送查询请求。
   - 权威域名服务器返回给本地 DNS 服务器目标域名对应的 IP 地址。
6. **返回结果**：
   - 本地 DNS 服务器将目标域名对应的 IP 地址返回给客户端，同时将查询结果保存在本地 DNS 缓存中，以便下次查询使用。

# 数据结构

## 排序算法

![](F:\study\tx\image\屏幕截图 2024-01-13 124606.png)

* ### 快速排序

快速排序是一种高效的排序算法，其基本思想是通过分治法（Divide and Conquer）将待排序的序列分成两部分，然后对每部分递归地进行排序，最终将结果合并起来。以下是快速排序的具体过程：

1. **选择基准元素**：
   - 从待排序的序列中选择一个元素作为基准元素。通常选择第一个元素、最后一个元素或者随机选择一个元素作为基准。
2. **划分操作**：
   - 将序列中所有比基准元素小的元素移到基准元素的左边，将比基准元素大的元素移到基准元素的右边。在划分的过程中，基准元素的位置也确定了。
3. **递归排序**：
   - 递归地对基准元素左边和右边的子序列进行排序。对左右子序列分别重复步骤1和步骤2，直到序列长度为1或0，即排序完成。
4. **合并结果**：
   - 将左右子序列排序后的结果合并起来，即完成了整个序列的排序。

```go
package main

import "fmt"

func quickSort(arr []int) {
    if len(arr) <= 1 {
        return
    }
    pivot := arr[0]
    left, right := 0, len(arr)-1
    for i := 1; i <= right; {
        if arr[i] < pivot {
            arr[left], arr[i] = arr[i], arr[left]
            left++
            i++
        } else {
            arr[right], arr[i] = arr[i], arr[right]
            right--
        }
    }
    quickSort(arr[:left])
    quickSort(arr[left+1:])
}

func main() {
    arr := []int{5, 9, 3, 6, 2, 8, 1, 7, 4}
    fmt.Println("Original array:", arr)
    quickSort(arr)
    fmt.Println("Sorted array:", arr)
}
```



## 56. 合并区间

```go
func merge(intervals [][]int) [][]int {
    sort.Slice(intervals, func (i, j int) bool{ return intervals[i][0] < intervals[j][0]})
    ans := make([][]int, 0)
    ans = append(ans, intervals[0])
    for _, e := range intervals[1:] {
        if ans[len(ans) - 1][1] < e[0] {
            ans = append(ans, e)
        } else {
            ans[len(ans) - 1][1] = max(ans[len(ans) - 1][1], e[1])
        }
    }
    return ans
}
```



## 最小路径和

```go
func minPathSum(grid [][]int) int {
    n := len(grid)
    m := len(grid[0])
    if n == 0 {
        return 0
    }
    // dp[i][j] 表示从左上角出发到(i,j)位置的最小路径和
    dp := make([][]int, n)
    for i, _ := range dp{
        dp[i] = make([]int, m)
    }
    for i := 0; i < n;i++ {
        for j := 0; j < m; j++ {
            if i == 0 && j == 0 {
                dp[i][j] = grid[i][j]
            } else if i == 0 && j != 0 {
                dp[i][j] = dp[i][j-1] + grid[i][j]
            } else if i != 0 && j == 0 {
                dp[i][j] = dp[i - 1][j] + grid[i][j]
            } else {
                dp[i][j] = min(dp[i-1][j], dp[i][j-1]) + grid[i][j]
            }
        }
    }
    return dp[n-1][m-1]
}
```

## 最长回文串

```go
func longestPalindrome(s string) string {
    n := len(s)
    dp := make([][]bool, n)
    for i, _ := range dp {
        dp[i] = make([]bool, n)
    }
    ans := ""
    // l为本次循环遍历的子串长度
    for l := 0; l < n; l++ {
        for i := 0; i + l < n; i++ {
            j := i + l
            if l == 0 {
                dp[i][j] = true
            } else if l == 1 {
                dp[i][j] = (s[i] == s[j])
            } else {
                dp[i][j] = (s[i] == s[j] && dp[i+1][j-1])
            }
            if dp[i][j] && l >= len(ans) {
                ans = s[i:j+1]
            }
        }
    }
    return ans
}
```

## 编辑距离

```go
/* 
本题要求将整个word1转换为整个word2所需要使用的最少操作数，
考虑将这一全局问题，
拆分成求word1的前i个字母组成的单词 
转换为 word2的前j个字母组成的单词 
所需要的最少操作数 这一子问题；
当子问题的规模扩大到i==len(word1)且j==len(word2)时，
该子问题的解就是全局问题的解，因此考虑使用动态规划
*/
func minDistance(word1 string, word2 string) int {
    //大小为m*n的状态数组dp，其中m=len(word1)+1，n=len(word2)+1
    m := len(word1) + 1
    n := len(word2) + 1
    dp := make([][]int, m)

    for i, _ := range dp {
        dp[i] = make([]int, n)
    }
    for i := 0; i < m; i++ {
        for j := 0; j < n; j++ {
            if i == 0 && j == 0 {
                dp[i][j] = 0
            } else if i == 0 && j != 0 {
                dp[i][j] = j
            } else if i != 0 && j == 0 {
                dp[i][j] = i
            } else {
                if word1[i-1] == word2[j-1] {
                    dp[i][j] = dp[i-1][j-1]
                } else {
                    dp[i][j] = min(dp[i-1][j-1], dp[i][j-1], dp[i-1][j]) + 1
                }
            }
        }
    }
    return dp[m-1][n-1]
}
/*
当word1的第i个字符与word2的第j个字符相等，即word1[i-1]==word2[j-1]：
此时在word1的前i-1个字符和word2的前j-1个字符已经转换完毕的基础上，无需再做任何操作，即dp[i][j]=dp[i-1][j-1]
当word1的第i个字符与word2的第j个字符不相等，即word1[i-1]!=word2[j-1]，存在以下3种情况：
替换：在word1的前i-1个字符和word2的前j-1个字符已经转换完毕的基础上，将word1的第i个字符替换为word2的第j个字符即可，即dp[i][j]=dp[i-1][j-1]+1

插入：在word1的前i个字符和word2的前j-1个字符已经转换完毕的基础上，在word1的后面插入word2的第j个字符即可，即dp[i][j]=dp[i][j-1]+1

删除：在word1的前i-1个字符和word2的前j个字符已经转换完毕的基础上，将word1的第i个字符进行删除即可，即dp[i][j]=dp[i-1][j]+1
由于要求最小操作数，因此dp[i][j]取上述3种情况的较小值
当规模增大到i==len(word1)，j==len(word2)时的子问题的解，就是要求的全局问题的解
*/
```

## 前k个高频

```go
func topKFrequent(nums []int, k int) []int {
	m := make(map[int]int)
	for i := 0; i < len(nums); i++ {
		m[nums[i]]++
	}
	sli := make([]int, 0)
	for k, v := range m {
		if len(sli) == 0 {
			sli = append(sli, k)
			continue
		}
		for j := 0; j < len(sli); j++ {
			if v >= m[sli[j]] {
                // 在切片任意位置插入元素
				sli = append(sli[:j], append([]int{k}, sli[j:]...)...)
				break
			}
			if j == len(sli)-1 {
				sli = append(sli, k)
                break
			}
		}
	}
    fmt.Println(sli)
	return sli[:k]
}
```

## 令牌桶

```go
package main

import (
	"fmt"
	"time"
)

type TokenBucket struct {
	capacity  int           // 令牌桶容量
	rate      int           // 令牌产生速率，单位为 tokens/second
	tokens    int           // 当前令牌数量
	lastToken time.Time     // 上一个令牌产生时间
}

func NewTokenBucket(capacity, rate int) *TokenBucket {
	return &TokenBucket{
		capacity:  capacity,
		rate:      rate,
		tokens:    capacity,
		lastToken: time.Now(),
	}
}

func (tb *TokenBucket) Allow() bool {
	now := time.Now()
	elapsed := now.Sub(tb.lastToken)
	tb.tokens += int(elapsed.Seconds()) * tb.rate
	if tb.tokens > tb.capacity {
		tb.tokens = tb.capacity
	}
	tb.lastToken = now

	if tb.tokens > 0 {
		tb.tokens--
		return true
	}
	return false
}
func main() {
	tb := NewTokenBucket(10, 5) // 令牌桶容量为10，令牌产生速率为5 tokens/second
	for i := 0; i < 20; i++ {
		if tb.Allow() {
			fmt.Println("Request", i, "allowed")
		} else {
			fmt.Println("Request", i, "denied")
		}
		time.Sleep(time.Second)
	}
}

```



## 实际问题

> 一亿个int类型的数字，怎么取top1w个，怎么用分布式的方案

单机方案（堆排序）：

1. **构建最小堆**：将一亿个数字构建成一个最小堆。
2. **依次取出最小堆的堆顶元素**：每次取出堆顶元素（即最小元素），将其放入一个容器中。
3. **重复步骤 2**：直到取出 1 万个最小元素。
4. **得到结果**：容器中的元素即为前 1 万个最大的数字。

分布式方案：

1. **数据分片**：将一亿个数字分成若干份，分布到多个节点上。
2. **各节点内部排序**：每个节点独立地对分配到的数据进行排序，可以选择快速排序等高效的排序算法。
3. **局部 Top-K**：每个节点取出排序后的前 1 万个最大数字。
4. **合并 Top-K**：将各节点得到的前 1 万个数字合并到一个集合中。
5. **全局排序**：对合并后的结果进行全局排序，得到最终的前 1 万个最大数字。

> 一千五百万行数据如何快速找到某一行数据，给出方案，设计数据库表结构

1. **数据库表结构设计**：
   - 选择一个能够快速查询的数据库，如 MySQL、PostgreSQL 等。
   - 设计一张包含至少两个字段的表：一个字段用于唯一标识行（如行号或主键），另一个字段用于存储数据。
   - 如果数据没有自然的唯一标识，可以使用自增的 ID 或者 UUID 来作为主键。

2. **索引**：
   - 在唯一标识行的字段上创建索引，以加速查找速度。
   - 如果需要按照数据内容进行查询，可以考虑在存储数据的字段上创建全文索引。

3. **分片**：
   - 如果数据量非常大，可以考虑将数据分片存储在多个数据库或表中，以减轻单个数据库的负担。
   - 可以按照某种规则（如哈希、范围等）将数据分散到不同的数据库或表中。

4. **缓存**：
   - 对于热门数据或频繁访问的数据，可以考虑使用缓存来加速查询。
   - 可以使用内存数据库如 Redis 来缓存查询结果，以减少数据库的负载和加快响应速度。

5. **优化查询**：
   - 对于频繁查询的数据，可以通过优化查询语句、使用合适的索引等手段来提高查询性能。
   - 可以通过分析查询日志和数据库性能来找出潜在的优化点，并针对性地进行优化。

6. **分页查询**

   ```sql
   SELECT * FROM `user_operation_log` WHERE id between 1000000 AND 1000100 LIMIT 100      
   SELECT * FROM `user_operation_log` WHERE id >= 1000000 LIMIT 100      
   ```

   

   

# Redis

## Redis为什么快

**内存存储**：

- Redis 将数据存储在内存中，而不是磁盘上，内存的读写速度远远快于磁盘，因此能够实现高速的读写操作。

**高效的数据结构**：

- Redis 提供了丰富的数据结构，如字符串、哈希、列表、集合、有序集合等，并针对不同的数据结构进行了优化，使得其在不同场景下能够提供高效的数据存储和操作。
- Redis 的数据结构都是基于内存的，操作速度非常快。

**基于reactor模式的IO模型：**

* Redis 内部使用epoll模型触发事件，将事件分发到事件分发器，分发器根据不同类型是事件来使用IO线程池，对于请求解析等执行会进行多线程的处理，对于执行命令事件是由主线程来进行。

## 超时淘汰（TTL Expiration）

Redis 中的超时淘汰（TTL Expiration）是指为键设置一个过期时间，当键在一定时间内未被访问或修改时，系统会自动将其删除，以节省内存空间。这个功能可以用于实现缓存、会话管理等场景。

* ## 实现原理：

1. **过期键的标记**：
   - 每个键都会关联一个过期时间（TTL），当设置了 TTL 后，Redis 会为键设置一个过期时间戳。
   - 过期时间戳存储在哈希表中，键是数据库中的键，值是对应的过期时间戳。
2. **过期键的检查**：
   - Redis 使用惰性删除和定期删除两种策略来删除过期键。
   - 惰性删除：当对一个键进行读写操作时，Redis 会先检查该键是否过期，如果过期则删除。
   - 定期删除：Redis 会定期地扫描数据库，删除过期的键。
3. **过期键的删除**：
   - 删除过期键的操作是异步执行的，Redis 会定期执行过期键的删除操作。
   - 删除过期键时，Redis 会检查键是否过期，如果过期则删除对应的键和过期时间戳。

* ## 数据结构实现：

Redis 使用字典（Dict）数据结构来存储键值对，其中键是一个字符串，值可以是不同的数据类型（如字符串、列表、集合等）。为了实现过期键的功能，**Redis 在字典的基础上，为每个键增加了一个额外的过期时间戳字段。**

- **过期时间戳字段**：存储在键的值中，用来记录键的过期时间。
- **过期键的检查和删除**：Redis 使用定时任务来检查和删除过期键，通过惰性删除和定期删除策略来保证过期键的及时删除。

## 数据删除策略

LRU是最近最少使用页面置换算法(Least Recently Used),也就是首先淘汰最长时间未被使用的页面!

LFU是最近最不常用页面置换算法(Least Frequently Used),也就是淘汰一定时期内被访问次数最少的页!

 volatile-lru：使用近似 LRU 算法移除，仅适用于设置了过期时间的 key。 

 allkeys-lru：使用近似 LRU 算法移除，可适用于所有类型的 key。 

 volatile-lfu：使用近似 LFU 算法移除，仅适用于设置了过期时间的 key。 

 allkeys-lfu：使用近似 LFU 算法移除，可适用于所有类型的 key。

 volatile-random：随机移除一个 key，仅适用于设置了过期时间的 key。

 allkeys-random：随机移除一个 key，可适用于所有类型的 key。

volatile-ttl：移除距离过期时间最近的 key。

noeviction：不移除任何内容，只是在写操作时返回一个错误，默认值

# go

1. **无锁 map 设计**：
   - 无锁 map 通常使用哈希表实现，使用原子操作和 CAS（Compare And Swap）等技术来保证并发安全。常见的无锁 map 实现包括 `concurrent-map`、`ccm` 等，它们通过细粒度的锁、分段锁或者基于 CAS 的操作来实现并发安全的 map。
2. **interface 底层实现**：
   - 在 Go 语言中，接口（interface）由两部分组成：类型信息和值信息。类型信息包含接口的方法集合，值信息包含接口的具体值。接口的底层实现是一个结构体，包含指向类型信息的指针和指向值信息的指针。当一个类型实现了接口的所有方法时，该类型的值可以赋给该接口类型的变量。
3. **channel 底层实现**：
   - Golang 中的 channel 是通过管道（channel）来实现的，底层是一个环形的队列结构。当向 channel 中发送数据时，数据被复制到 channel 的缓冲区中；当从 channel 中接收数据时，数据被从缓冲区中取出并返回。channel 的操作是原子的，因此可以安全地在多个 Goroutine 中进行读写操作。
4. **关闭 channel 的影响**：
   - 当一个 channel 被关闭后，读取该 channel 的 Goroutine 会在读取完所有剩余的数据后立即返回，并且会返回一个零值和一个表示 channel 已关闭的标志；写入该 channel 的 Goroutine 会继续写入数据直到 channel 的缓冲区满为止，之后会引发 panic。
5. **select 使用场景**：
   - `select` 语句用于处理一个或多个 channel 的读写操作，以实现非阻塞的 IO 操作或者多路复用。常见的使用场景包括等待多个 channel 中的任意一个可读写、超时控制、实现优雅的退出等。`select` 语句可以使程序更加高效、简洁和可读。

## gin原理

- gin 将 Engine 作为 `http.Handler `的实现类进行注入，从而融入 Golang net/http 标准库的框架之内
- gin 中基于 handler 链的方式实现中间件和处理函数的协调使用
- gin 中基于压缩前缀树的方式作为路由树的数据结构，对应于 9 种 http 方法共有 9 棵树
- gin 中基于 `gin.Context` 作为一次 http 请求贯穿整条 handler chain 的核心数据结构
- `gin.Context` 是一种会被频繁创建销毁的资源对象，因此使用对象池 sync.Pool 进行缓存复用

# 个人优势

我认为我的主要优势在于几个方面。首先，我拥有扎实的技术背景和深厚的编程能力。我对各种后端技术栈有着广泛的了解，并且能够快速学习和适应新的技术。这使得我能够在面对各种技术挑战时迅速找到解决方案，并编写高效可靠的代码。

其次，我具备良好的团队合作能力。我乐于与他人合作，并且能够有效地与团队成员沟通和协作，共同解决问题。我认为一个团队的成功不仅仅取决于个人的能力，更取决于团队成员之间的合作和协调。

最后，我有很强的问题解决能力。在遇到困难或挑战时，我喜欢积极主动地寻找解决方案，并且愿意尝试不同的方法来解决问题。我相信这种乐于挑战和不断探索的态度将使我在面对各种复杂的工程问题时能够保持冷静并找到最佳的解决方案