# 网络IO

## 广播地址

- 广播地址是指在特定网络上发送广播消息的地址。**它用于向网络上的所有设备发送信息**。**广播地址通常是某个网络的最大可能地址，将主机号部分全部设置为1**。例如，在 IP 地址为192.168.0.0，IP掩码为255.255.255.0 的情况下，广播地址就是192.168.0.255。
- 广播地址在 IP 地址中用于向同一网络内的所有设备发送消息或数据包。它是一个特殊的地址，使得发送到该地址的数据包将被网络上的所有设备接收。
- 广播通常用于一些特定的场景，比如局域网中的设备发出某个请求，希望获得同一网络下的所有设备的响应。一个常见的例子是 DHCP（动态主机配置协议）服务器，在启动时会向整个网络广播一个 DHCP 请求，以获取静态 IP 地址分配。同样地，ARP（地址解析协议）也使用广播来查找与给定 IP 地址关联的 MAC 地址。
- 举个例子，假设你的局域网中有四台计算机，它们的 IP 地址范围是：192.168.0.1 - 192.168.0.4，子网掩码为 255.255.255.0。如果你想向整个局域网发送一个广播消息，你可以将目标地址设置为 192.168.0.255，这是该网络的广播地址。这样，所有四台计算机都能够接收到该消息，并根据需要作出响应。
- 需要注意的是，广播只会在同一网络中传播，因此不会跨越路由器或互联网边界。所以，这仅适用于发送到同一局域网内的设备。

## 子网掩码

子网掩码的功能总结

通过以上的讲述，我们知道了子网掩码有两个功能

1. **将一个IP地址划分为网络位和主机位**
2. **判断IP是否在同一个子网以及划分子网**

什么是子网掩码
在我们之前的文章中，讨论了如何通过A到E的分类来划分IP地址的网络位和主机位，以及由此产生的资源浪费和低效率问题。为了解决这些问题，子网掩码应运而生（值得注意的是，A到E的分类仍然存在）。

IP地址本身不再记录划分信息，而是通过一个独立的数字序列来辅助标记，这就是子网掩码。

这个序列同样由32位二进制组成，例如：

```
11111111 11111111 11111111 00000000 
```

连续的1代表网络位，连续的0代表主机位。

但在展示时通常转化为十进制形式，例如上面的转化为十进制后：

```
255.255.255.0
```

转换后前三组的255，就表示一个IP地址中前三组数是网络号，而最后一组的0表示一个IP地址中后一组是主机号。比如我这里有一个IP地址以及它对应的子网掩码：

```
// IP：
192.168.33.112  
// 子网掩码：
255.255.255.0
```

说明这个IP地址192.168.33是网络位，112 是主机位。这就子网掩码的功能之一。

接着来介绍子网掩码的另外一个作用：判断设备是否在同一个子网！

什么是子网
先大致的了解一下什么是子网。

比如两台笔记本电脑连接同一个WIFI，那么他们就在同一个子网中或者说是同一个局域网中，即使路由器断开外网连接，这两台电脑仍能够相互通讯。

如何判断是否在同一个子网
前面提到子网掩码可以判断设备是否在同一个子网，怎么判断呢？

假如我们有一台A笔记本，一台B笔记本，不知道连接的是不是同一个WIFI，可以通过查询我们得知：

A笔记本的信息如下：

```
// IP：
192.168.33.112 
// 子网掩码：
255.255.255.0
```

B笔记本的信息如下：

```
// IP：
192.168.33.223
// 子网掩码：
255.255.255.0
```

**通过IP地址的二进制格式与子网掩码的二进制格式进行and运算，如果相等，说明AB笔记本处于同一个子网，同一个WIFI，可以直接通信**。

来来来，我们来算下，先算A笔记本：

```
11000000 10101000 00100001 01110000 // IP
11111111 11111111 11111111 00000000 // 子网掩码
// and运算理解为位相乘就可以了，上下每一位都相乘得
11000000 10101000 00100001 00000000
// 转成十进制为
192.168.33.0
```

同理B运算完并转成十进制后为：

```
192.168.33.0
```

A和B笔记本的运算结果相等，证明在同一个子网。

当然我们不会每次比较两个设备的时候都去这么计算，有子网掩码的分类快速去判断。

子网掩码的分类
首先子网掩码有如下分类：

A类：255.0.0.0
B类：255.255.0.0
C类：255.255.255.0
如果一个IP地址192.172.3.64配套的子网掩码是255.255.255.0，那么这个IP就是属于C类，也就是说IP的最后一组是主机位，那么可能在同个子网下所有设备的IP地址范围为192.172.3.0 ~ 192.172.3.255。

但在这个范围内：

192.172.3.0是网络地址，用于标识子网本身，不分配给任何设备。
192.172.3.255是广播地址，用于发送到该子网内所有设备的广播消息。
其余的地址（192.172.3.1到192.172.3.254）可以分配给子网内的设备。
当然，比之前的IP分类灵活的地方在于每一类还可以继续划分子网，被称为可变长子网掩码

可变长子网掩码
比如C类中，我想再划分出子网，可以通过网络位的扩展，占用主机位：

255.255.255.128 (/25) - 二进制表示：11111111.11111111.11111111.10000000
255.255.255.192 (/26) - 二进制表示：11111111.11111111.11111111.11000000
255.255.255.224 (/27) - 二进制表示：11111111.11111111.11111111.11100000
255.255.255.240 (/28) - 二进制表示：11111111.11111111.11111111.11110000
255.255.255.248 (/29) - 二进制表示：11111111.11111111.11111111.11111000
255.255.255.252 (/30) - 二进制表示：11111111.11111111.11111111.11111100
255.255.255.254 (/31) - 二进制表示：11111111.11111111.11111111.11111110
255.255.255.255 (/32) - 二进制表示：11111111.11111111.11111111.11111111
有点懵？我们慢慢来，就拿第二个举例好了，通过二进制表示我们可以看出，原本主机位前两个00变成了11，这是因为网络位扩展了，占用了2个主机位。此时网络位个数为8+8+8+2=26，主机位为8-2=6个。

所以255.255.255.192 (/26) 就表示这个是个可变长子网掩码，且网络位为26。当然真正电脑里展示的子网掩码只会是255.255.255.192。

一般我们写IP地址为了突出子网掩码的信息，可以这么写：192.168.11.30/26，从后面这个/26就能够看出是一个C类的可变长子网。

注意了！子网掩码必须是连续的1后面跟着连续的0，在二进制中不能有1和0交错的情况。例如不能是：11111111.11111111.11111111.00111111

那255.255.255.192究竟划分了几个子网呢？只需要看被占用的主机位有多少种组合，例如00，10，01，11，也就是划分了4个子网。对应到IP地址的最后一组分别为：

00情况下的00000000-00111111 转为 0-63
01情况下的01000000-01111111 转为 64-127
10情况下的10000000-10111111 转为128-191
11情况下的11000000-11111111 转为192-255
假设我有个IP地址的主机位是192.163.1，子网的地址范围将是：

第一个子网：192.163.1.0 到 192.163.1.63
第二个子网：192.163.1.64 到 192.163.1.127
第三个子网：192.163.1.128 到 192.163.1.191
第四个子网：192.163.1.192 到 192.163.1.255
在每个子网中：

第一个地址（如192.163.1.0, 192.163.1.64, 等）是子网的网络地址，用于标识子网，不分配给设备。
最后一个地址（如192.163.1.63, 192.163.1.127, 等）是子网的广播地址，用于发送到该子网内所有设备的广播消息。
其余的地址（如192.163.1.1到192.163.1.62, 192.163.1.65到192.163.1.126, 等）可以分配给子网内的设备。

## IP报文

![](image\Screenshot 2024-07-17 152040.png)

1、版本（4位）

IP协议的版本，目前的IP协议版本号为4，下一代IP协议版本号为6。

2、首部长度（4位）

IP报头的长度。固定部分的长度（20字节）和可变部分的长度之和。共占4位。最大为1111，即10进制的15，代表IP报头的最大长度可以为15个32bits（4字节），也就是最长可为15*4=60字节，除去固定部分的长度20字节，可变部分的长度最大为40字节。

3、服务类型（8位）

用来获得更好的服务。其中的前3位表示报文的优先级，后面的几位分别表示要求更低时延、更高的吞吐量、更高的可靠性、更低的路由代价等。对应位为1即有相应要求，为0则不要求。

4、总长度（16位）

IP报文的总长度。报头的长度和数据部分的长度之和。注意这里的单位为字节，而不是4字节，所以一个IP报文的的最大长度为65535个字节。

5、标识（16位）

唯一的标识主机发送的每一分数据报。通常每发送一个报文，它的值加一。当IP报文长度超过传输网络的MTU（最大传输单元）时必须分片，这个标识字段的值被复制到所有数据分片的标识字段中，使得这些分片在达到最终目的地时可以依照标识字段的内容重新组成原先的数据。

6、标志（3位）

共3位。R、DF、MF三位。目前只有后两位有效，DF位：为1表示不分片，为0表示分片。MF：为1表示“更多的片”，为0表示这是最后一片。

7、片位移（13位）

指当前分片在原数据报（分片前的数据报）中相对于用户数据字段的偏移量，即在原数据报中的相对位置。（需要再乘以8）

8、生存时间（8位）

TTL（Time to Live）。该字段表明当前报文还能生存多久。每经过1ms或者一个网关，TTL的值自动减1，当生存时间为0时，报文将被认为目的主机不可到达而丢弃。TTL 字段是由发送端初始设置一个 8 bit字段.推荐的初始值由分配数字 RFC 指定，当前值为 64。发送 ICMP 回显应答时经常把 TTL 设为最大值 255。

9、协议（8位）

指出IP报文携带的数据使用的是那种协议，以便目的主机的IP层能知道要将数据报上交到哪个进程（不同的协议有专门不同的进程处理）。和端口号类似，此处采用协议号，TCP的协议号为6，UDP的协议号为17。ICMP的协议号为1，IGMP的协议号为2.

10、首部校验和（16位）

用于检验IP报文头部在传播的过程中是否出错，检查IP报头的完整性。

11、源IP地址（32位）

标识IP数据报的源端设备。

12、目的IP地址（32位）

标识IP数据报的目的地址。



## UDP协议

![](.\image\Screenshot 2024-07-17 154102.png)

## TCP协议

> TCP(Transmission control protocol)即传输控制协议，是一种**面向连接、可靠的**数据传输协议。

* ### TCP报文结构

  ![](image\屏幕截图 2024-01-09 055949.png)

* ### 三次握手（建立连接）

![](image\屏幕截图 2024-01-09 054836.png)

**第一次握手** TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x **序号(sequence number)**，此时，TCP客户端进程进入了 **SYN-SENT** 同步已发送状态

**第二次握手** TCP服务器收到请求报文后，如果同意连接，则会向客户端发出确认报文。确认报文中应该 ACK=1（表示合法），SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了 **SYN-RCVD** 同步收到状态

**第三次握手** TCP客户端收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入**ESTABLISHED已建立连接状态** 触发三次握手



* ### 四次挥手(关闭连接)

  ![](image\屏幕截图 2024-01-09 055203.png)

  **第一次挥手** 客户端发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入**FIN-WAIT-1（终止等待1）**状态

  **第二次挥手** 服务器端接收到连接释放报文后，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了**CLOSE-WAIT 关闭等待状态**

  **第三次挥手** 客户端接收到服务器端的确认请求后，客户端就会进入**FIN-WAIT-2（终止等待2）**状态，等待服务器发送连接释放报文。服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，服务器就进入了**LAST-ACK（最后确认）**状态，等待客户端的确认。

  **第四次挥手** 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了**TIME-WAIT（时间等待）**状态，但此时TCP连接还未终止，必须要经过2MSL后（最长报文寿命），当客户端撤销相应的TCB后，客户端才会进入**CLOSED关闭状态**。服务器端接收到确认报文后，会立即进入**CLOSED关闭状态**，到这里TCP连接就断开了，四次挥手完成



## TCP拥塞控制

> 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变差，这种情况就叫做网络拥塞。
>
> 若**出现拥塞而不进行控制**，整个网络的**吞吐量将随输入负荷的增大而下降**。路由器缓存溢出，拥塞会导致丢包。

![](image\屏幕截图 2024-01-13 120149.png)



* ### TCP四种拥塞控制算法

  1. 慢开始
  2. 拥塞避免
  3. 快重传
  4. 快恢复

* ### 拥塞控制过程

  > 假定：
  >
  > 1. 数据是单方向传送的，而另一个方向只传送确认
  > 2. 接收方总是有足够大的缓存空间，因而发送发发送窗口的大小由网络的拥塞程度来决定
  > 3. 以TCP报文段的个数为讨论问题的单位，而不是以字节为单位

  * #### 慢启动

  ![](image\屏幕截图 2024-01-13 121346.png)

  慢启动会**指数**地增加拥塞窗口的大小，直到超过或等于`ssthreash`，就用拥塞避免算法。

  慢启动，累积确认，每收到一个确认报文就会增加一，所以是指数增长。

  当拥塞窗口大于慢开始门限（ssthresh），就会触发拥塞避免算法，拥塞窗口cwnd只能线性加一线性增加拥塞窗口大小。

  当收到3个重复ACK（即重传），就会发生块重传和快恢复机制。

  * #### 拥塞避免

    ![](image\屏幕截图 2024-01-13 122538.png)

    拥塞避免算法会**线性**增加拥塞窗口大小，直到发生重传（收到三次重复确认），即快重传，之后就会发生快重传。将`ssthreash`设置为发生拥塞时的`cwnd`的一半

  * 快重传

    发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传时再重传。

  * 快恢复

    * 当发送端收到第三个重复确认的报文时，会更新ssthresh的值，然后立即重传丢失的报文段，并且设置：cwnd = ssthresh+3*SMSS，进入拥塞避免阶段。
    * 当收到一个重复确认的报文时，设置cwnd = cwnd +SMSS。此时发送端可以发送新的TCP报文（如果新的cwnd允许）
    * 当收到新数据的确认时，设置cwnd=ssthresh。进入拥塞避免阶段。

> 新的TCP Reno 版本在快重传之后采用快回复算法而不是采用慢开始

#### 拥塞控制窗口和流量控制窗口的区别

> 两者作用上的区别:
>
> 流量控制是为了解决发送方和接收方速度不同而导致的数据丢失问题,当发送方发送的太快,接收方来不及接受就会导致数据丢失,流量控制用滑动窗口的形式解决问题
>
> 拥塞控制是为了解决过多的数据注入到网络,导致网络奔溃,超过负荷.当发送方发送数据大量的数据会注入到网络,如果没有限制,网络就会超负荷变卡,拥塞控制的用的是拥塞窗口解决的问题的







## IO 多路复用机制

> 首先IO多路复用会提交一批需要监听的[文件句柄](https://www.zhihu.com/search?q=文件句柄&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3015478357})（socket也是一种文件句柄）到内核，由内核开启一个线程负责监听，把轮询工作交给内核，当有事件发生时，由内核通知用户程序。这不需要用户程序开启更多的线程去处理连接，也不需要用户程序切换到内核态去轮询，用一个线程就能处理大量网络IO请求

对于多路复用器的多路选择算法常见的有三种：select 模型、poll 模型、epoll 模型。

|              | select                                                       | poll                                                         | epoll                                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------- |
| 性能         | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能基本没有变化                |
| 连接数       | 一般1024                                                     | 无限制                                                       | 无限制                                            |
| 内存拷贝     | 每次调用select拷贝                                           | 每次调用poll拷贝                                             | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 数据结构     | bitmap                                                       | 数组                                                         | 红黑树                                            |
| 内在处理机制 | 线性轮询                                                     | 线性轮询                                                     | FD挂在红黑树，通过事件回调callback                |
| 时间复杂度   | O(n)                                                         | O(n)                                                         | O(1)                                              |

* ### select 函数

  ```c
  select(int nfds, fd_set *r, fd_set *w, fd_set *e, struct timeval *timeout)
  ```

  想要使用这个方法，首先可以看出要传入三个集合，这个集合都是`bitmap`类型的，分别表示`readfds，writefds，exceptfds`，读、写、异常集合。通过`0/1`来表示集合对应位置的**fd（file description 文件描述符）**是否关心对应事件。

  当用户进程调用select方法后，就会进入阻塞，然后就会开始轮询集合，直到集合中就绪的fd到达设置的阈值，或者超时，函数返回。返回后可以通过遍历集合来处理对应fd请求。

  select存在的问题：

  1. 大小有限制。为1024，由于每次select函数调用都需要在用户空间和内核空间传递这些参数，为了提升拷贝效率，linux限制最大为1024。
  2. 每次调用 select() 时，需要把 fd 数据从用户态拷贝到内核态，频繁复制开销很大；
  3. 每次遍历集合有哪些事件发生，效率低下。

* ### poll 函数

  ```c
  poll(struct pollfd *fds, int nfds, int timeout)
  
  struct pollfd {
  	int fd;
  	short events;
  	short revents;
  }
  ```

  poll函数需要传一个pollfd结构数组，其中fd表示文件描述符，events表示关心的事件，revents表示发生的事件，当有事件发生时，内核通过这个参数返回回来。

  poll相比select的改进：

  1. 传不固定大小的数组，没有1024的限制了（问题1）
  2. 将关心的事件和实际发生的事件分开，不需要每次都重新设置参数（问题2）。例如poll数组传1024个fd和事件，实际只有一个事件发生，那么只需要重置一下这个fd的revent即可，而select需要重置1024个bit。

  poll没有解决select的问题3和4。另外，虽然poll没有1024个大小的限制，但每次依然需要在用户和内核空间传输这些内容，数量大时效率依然较低。

  这几个问题的根本实际很简单，核心问题是[select/poll方法](https://www.zhihu.com/search?q=select%2Fpoll方法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3015478357})对于内核来说是无状态的，内核不会保存用户调用传递的数据，所以每次都是全量在用户和内核空间来回拷贝，如果调用时传给内核就保存起来，有新增文件描述符需要关注就再次调用增量添加，有事件触发时就只返回对应的文件描述符，那么问题就迎刃而解了，这就是epoll做的事情。

* ### Epoll 

  ```c
  int epoll_create(int size);
  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
  int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
  typedef union epoll_data {
     void *ptr;
     int fd;
     uint32_t u32;
     uint64_t u64;
  }epoll_data_t;
  
  struct epoll_event {
     uint32_t events;   // epoll events
     epoll_data_t data; // user data variable
  }
  ```

  - epoll_create() 系统启动时，在 Linux 内核里创建 epoll 实例（申请一个红黑树 rbTree 和就绪链表 readyList），以便存放 socket 节点；

  - epoll_ctl() 每新建一个连接，都通过该函数操作 epoll 对象，在这个对象的红黑树里增、删、改对应的 socket 节点，绑定一个回调函数；

  - epoll_wait() 轮询所有的回调集合，并完成对应的 IO 操作。相应分三步：

  - - 阻塞线程
    - 内核查找红黑树中准备好的 socket，放入就绪链表 rdlist
    - 就绪列表中的内容复制到 events（从内核态复制到用户态），准备循环处理这些已就绪的 socket 节点

  - **epoll模型又有LT和ET模式**

  - LT 和 ET：

  - - LT，level triggered，水平触发，又叫条件触发。当被监控的 fd 上有可读写的事件时，epoll_wait() 会通知处理程序去读写。如果这次没有把数据一次性全部读写完，那么下次调用 epoll_wait() 时，它还会通知你上次没有读写完的 fd，可继续读写。而且我们不需要读写的 fd，它也会一直通知你。
    - ET，edge triggered，边缘触发。当被监控的 fd 上有可读写事件时，epoll_wait() 会通知处理程序去读写。如果这次没有把数据全部读完，下次将不再通知。
    - 学过计算机组成原理的应该知道脉冲信号，其实 ET 和 LT 的原理和电信号的变化差不多。LT 就是只有高电平(1)或低电平(0)时才触发通知，只要在指定的状态上，就会得到通知；ET 是只有电平发生变化时(从高电平到低电平，或者从低到高)，才触发通知。



## Reactor 模式

> IO多路复用是操作系统的底层实现，借助IO多路复用我们实现了一个线程就可以处理大量网络IO请求，那么接收到这些请求后该如何高效的响应，这就是reactor要关注的事情，reactor模式是基于事件的一种[设计模式](https://www.zhihu.com/search?q=设计模式&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3015478357})。在reactor中分为3中角色：
> **Reactor**：负责监听和分发事件
> **Acceptor**：负责处理连接事件
> **Handler**：负责处理请求，读取数据，写回数据

从线程的角度出发，reactor又可以分为单reactor单线程，单reactor多线程，多reactor多线程3种。

* ### 单Reactor单线程

  ![image-20240109072922285](C:\Users\13218\AppData\Roaming\Typora\typora-user-images\image-20240109072922285.png)

  处理过程：reactor负责监听连接事件，当有连接到来时，通过acceptor处理连接，得到建立好的socket对象，reactor监听scoket对象的读写事件，读写事件触发时，交由handler处理，handler负责读取请求内容，处理请求内容，响应数据。

* ### 单reactor多线程

  ![](image\屏幕截图 2024-01-09 072947.png)

  既然处理请求这里可能由性能问题，那么这里可以开启一个线程池来处理，这就是单reactor多线程模式，请求连接、读写还是由主线程负责，处理请求内容交由线程池处理，相比之下，多线程模式可以利用cpu多核的优势。单仔细思考这里依然有性能优化的点，就是对于请求的读写这里依然是在主线程完成的，如果这里也可以多线程，那效率就可以进一步提升。

* ### 多reactor多线程

  ![](image\屏幕截图 2024-01-09 073048.png)

  多reactor多线程下，mainReactor接收到请求交由acceptor处理后，mainReactor不再读取、写回网络数据，直接将请求交给**subReactor线程池处理**，这样读取、写回数据多个请求之间也可以并发执行了。



### Redis 网络IO模型

> redis网络IO模型也用到了Reactor模式实现的，只不过有一些不一样。

* #### 单线程模式

在redis6.0以前属于单Reactor单线程的模式。如图：

![](image\屏幕截图 2024-01-09 073940.png)

在Linux下，IO多路复用程序使用**epoll**实现的，负责监听服务端连接、socket的读取、写入事件等，然后将事件丢到**事件队列**中去。

以一个简单的`get key` 简单命令为例。

![](image\屏幕截图 2024-01-09 074827.png)

当redis服务器启动时，主线程运行，监听指定的端口，**将连接事件绑定命令应答处理器**。

客户端请求连接时，就会触发连接事件，IO多路复用程序将连接事件放入事件队列，事件分发起就会交由命令应答处理器处理请求：**创建socket，将ae_readable(可读事件)关联命令请求处理器，交由IO多路复用程序监听**

连接建立之后，就开始执行命令。

![](image\屏幕截图 2024-01-09 145543.png)

客户端发送`get key`命令，**socket接收到数据变成可读，这时IO多路复用程序就会监听到可读事件，将事件放入事件队列，有事件分发器分发给之前绑定的命令请求处理器执行**。

命令请求处理器**接收到数据后，解析数据，执行get命令，从内存中查询到key对应的数据，并将ae_writeable（写入事件）关联命令应答处理器，交由IO多路复用程序监听**

当客户端准备好接收数据时，**命令请求处理器命令请求处理器产生ae_writeable事件，IO多路复用程序监听到写事件，将写事件丢到事件队列，由事件分发器发给命令响应处理器进行处理。**命令响应处理器将数据写回socket返回给客户端。

* #### 多线程模式

redis 6.0多线程模型思想上类似单reactor多线程和多reactor多线程，但不完全一样，这两者handler对于逻辑处理这一块都是使用线程池，而redis命令执行依旧保持单线程。如下：

![](image\屏幕截图 2024-01-09 075351.png)

**多线程 IO 模型中的“多线程”仅用于接受、解析客户端的请求，然后将解析出的请求 写入到任务队列。而对具体任务（命令）的处理，仍是由主线程处理**



## http和https的区别

HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。

　　HTTPS和HTTP的区别主要如下：

　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。



##  SSL是什么意思

> SSL(Secure Sockets Layer 安全套接层)及其继任者传输层安全(Transport Layer Security，TLS)是为网络通信提供安全及数据完整性的一种安全协议。如今被广泛使用，如网页，电子邮件，互联网传真，即时消息和语音在IP电话（VoIP）。其中网站是通过使用TLS来保护WEB浏览器与服务器之间的通信安全。

**SSL (Secure Socket Layer)**

为Netscape所研发，用以保障在Internet上数据传输之安全，利用数据加密(Encryption)技术，可确保数据在网络上之传输过程中不会被截取及窃听。

SSL协议位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。

**SSL协议可分为三层：**

SSL握手协议(SSL Handshake Protocol)：握手协议是客户机和服务器用SSL连接通信时使用的第一个子协议，握手协议包括客户机与服务器之间的一系列消息。SSL中最复杂的协议就是握手协议。该协议允许服务器和客户机相互验证，协商加密和MAC算法以及保密密钥，用来保护在SSL记录中发送的数据。握手协议是在应用程序的数据传输之前使用的。

SSL记录协议(SSL Record protocol)：记录协议在客户机和服务器握手成功后使用，即客户机和服务器鉴别对方和确定安全信息交换使用的算法后，进入SSL记录协议，记录协议向SSL连接提供两个服务：

（1）保密性：使用握手协议定义的秘密密钥实现

（2）完整性：握手协议定义了MAC，用于保证消息完整性

SSL警报协议(SSL Handshake Protocol)：客户机和服务器发现错误时，向对方发送一个警报消息。如果是致命错误，则算法立即关闭SSL连接，双方还会先删除相关的会话号，秘密和密钥。每个警报消息共2个字节，第1个字节表示错误类型，如果是警报，则值为1，如果是致命错误，则值为2；第2个字节制定实际错误类型。

**SSL协议提供的服务主要有：**

1)认证用户和服务器，确保数据发送到正确的客户机和服务器;

2)加密数据以防止数据中途被窃取;

3)维护数据的完整性，确保数据在传输过程中不被改变。

**SSL协议的工作流程：**

1：客户端的浏览器向服务器传送客户端 SSL 协议的版本号，加密算法的种类，产生的**随机数1**，以及其他服务器和客户端之间通讯所需要的各种信息。

2：服务器向客户端传送 SSL 协议的版本号，加密算法的种类，**随机数2**以及其他相关信息，同时服务器还将向客户端传送自己的证书。

3：客户利用服务器传过来的信息验证服务器的合法性，服务器的合法性包括：证书是否过期，发行服务器证书的 CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配。如果合法性验证没有通过，通讯将断开；如果合法性验证通过，将继续进行第四步。

4：**用户端随机产生一个用于后面通讯的“对称密码”，然后用服务器的公钥（服务器的公钥从步骤②中的服务器的证书中获得）对其加密，然后将加密后的“预主密码”传给服务器。**

5：如果服务器要求客户的身份认证（在握手过程中为可选），用户可以建立一个随机数然后对其进行数据签名，将这个含有签名的随机数和客户自己的证书以及加密过的“预主密码”一起传给服务器。

6：如果服务器要求客户的身份认证，服务器必须检验客户证书和签名随机数的合法性，具体的合法性验证过程包括：客户的证书使用日期是否有效，为客户提供证书的CA 是否可靠，发行CA 的公钥能否正确解开客户证书的发行 CA 的数字签名，检查客户的证书是否在证书废止列表（CRL）中。检验如果没有通过，通讯立刻中断；如果验证通过，服务器将用自己的私钥解开加密的“预主密码”，然后执行一系列步骤来产生主通讯密码（客户端也将通过同样的方法产生相同的主通讯密码）。

7：服务器和客户端用相同的主密码即“通话密码”，一个对称密钥用于 SSL 协议的安全数据通讯的加解密通讯。同时在 SSL 通讯过程中还要完成数据通讯的完整性，防止数据通讯中的任何变化。

8：客户端向服务器端发出信息，指明后面的数据通讯将使用的步骤⑦中的主密码为对称密钥，同时通知服务器客户端的握手过程结束。

9：服务器向客户端发出信息，指明后面的数据通讯将使用的步骤⑦中的主密码为对称密钥，同时通知客户端服务器端的握手过程结束。

10：SSL 的握手部分结束，SSL 安全通道的数据通讯开始，客户和服务器开始使用相同的对称密钥进行数据通讯，同时进行通讯完整性的检验。





HTTPS 中的 S代表的是SSL/TLS，SSL是TLS的前身，现在大多数浏览器只支持TLS了。

**对称加密：**

通信双方都用同样的解密规则来对密码进行加解密。

**被对称加密：**

服务端有一个私钥和一个公钥。公钥让客户端知道。

加密规则是：

数据经过公钥加密后，只能被私钥解密。

数据经过私钥加密后，只能被公钥解密

> SSL证书

SSL证书是由特定机构（大家都认可的证书机构）发送给网站的，里面记录了服务器的公钥、所属域名等信息，在服务器安装SSL证书，就可以通过HTTPS来访问服务器了。（HTTPS的默认端口443）

HTTPS请求过程：

![](image\屏幕截图 2024-02-17 235521.png)

**由于会话密钥没有被非加密传输，是非常安全的。故得到会话密钥后，通信双方就只使用对称加密来进行数据传输，减小开销**

用户端随机产生一个用于后面通讯的“对称密码”，然后用服务器的公钥（服务器的公钥从步骤②中的服务器的证书中获得）对其加密，然后将加密后的“预主密码”传给服务器。

### 没有https的缺点：

1. 无法进行身份验证，无法保证访问的页面是否为官方地址。 
2. 不能保证数据的完整性，可能会被更改。
3. 保证不了数据的机密性，容易泄密。

## CA数字证书

> 服务器发送的用于用户加密的密钥可能会被黑客截胡篡改，这时就需要第三方来保证密钥的可靠性，这时就出现了CA数字证书

网站需要先把用来给你加密的公钥放在大家都信任的第三方CA那里，第三方CA就会根据这把公钥以及其它信息生成了“数字证书”。

> 这时又出现问题了，我们如何相信“数字证书”就是由信任的CA颁发的呢？
>
> “数字证书”上有CA的数字签名就可以了。当CA收到服务器的信息以及公钥以后，会对这些信息进行哈希运算（SHA256），然后获得一串较短的字符串（便于传输和加密解密）；这时CA会生成一对私钥和公钥，然后用**私钥**再对这个字符串进行加密，这就生成数字签名。

客户端收到数字证书后，会用CA公钥来解密数字签名，然后对证书上的内容同样进行哈希运算（SHA256），然后比较数字签名和证书上的信息是否一致。（只有拥有私钥才能够同时修改两者）。

> 问题又又又出现了，客户端如何拿到CA公钥的呢？而服务器又怎么保证拿到的证书是安全可靠的呢？
>
> CA证书同样也需要一个证书来证明自己的可靠性，然后把这个CA公钥放入到证书里面，即根CA。然后根CA的证书由自己加密，然后在用户操作系统和浏览器里面预先安装根CA的证书（有公钥）。



## HTTP/1.1,HTTP/2和HTTP/3的区别

### http1.1

http1.1的核心就是一次请求一次响应。

会有http队头阻塞问题

### http2

使用了多路复用技术。

把报文首部和报文主体都分成一个个二进制的帧（首部帧和数据帧），分开传输，用流标识符来按照顺序进行组合。（二进制解析起来很快）

把首部也给压缩了。（HPACK算法），浏览器和服务器都保存一张静态只读的表。

只解决了http层面的队头阻塞问题，还是有TCP队头阻塞问题。

### http3

核心：整合

http/3把TCP和TLS的握手过程整合在一起了。新推出了一个新的协议QUIC，这个协议整合了TCP和TLS，然后传输层使用UDP（为了广泛适用）。数据会被封装成QUIC帧，然后又会被封装成一个QUIC数据包，这个数据包维护有一个连接ID（如何网络发生变化，可以不用再次进行握手），最后被UDP封装成数据段。



## XSS

> Cross Site Scripting 跨站脚本

攻击者通过一些手段（木马程序）在用户访问的网页html中加入预定义好的脚本，这个脚本可能会盗取用户的数据和隐私。



防御：

对输入（和URL参数）进行过滤，对输出进行编码Cookie 设置 http-only



## CSRF（跨站请求伪造漏洞）

> **CSRF(Cross-Site Request Forgery)**，跟XSS漏洞攻击一样，存在巨大的危害性
>
> 你可以这么来理解：攻击者盗用了你的身份，以你的名义发送恶意请求，对服务器来说这个请求是完全合法的，但是却完成了攻击者所期望的一个操作，比如以你的名义发送邮件、发消息，盗取你的账号，添加系统管理员，甚至于购买商品、虚拟货币转账等

黑客会伪造一个网站，当你进入网站时，就会触发请求，如果这个请求资源路径没有CSRF防御，并且你的登陆cookie并没有失效，就能对你的用户进行非法操作。

**防御手段：**

1. 加入验证码，这时最有效简单的请求。
2. 验证 Referer，即HTTP协议带的参数，即请求来源，服务端可以验证请求来源来防御；但是有些浏览器可以修改这个属性，所以这个方法并不是最好的
3. Anti CSRF Token，每次访问网站时，服务端都会发送并记录在服务端一个token来验证请求中是否带上这个防御token，这也可以说是另一种验证码。
4. 加入自定义的 Header与上面的方法类似



## 代理和VPN

> ### 代理和VPN的目的

代理服务器（之后简称为：代理）和VPN的效果都是一样的——**向目标服务器隐藏IP**。当你向服务器发送一个请求时，网站所在的服务器可以根据你的IP地址来推断你的位置。

> ### 代理服务器简介

所谓代理服务器，就是你发送请求的对象是代理服务器，你和代理服务器之间发送消息，代理服务器在向目标服务器进行数据传递。

**代理的工作原理是**：由代理服务器自己去访问你的目标网站，并加载它的内容，然后再把这些加载过的内容传递到你的窗口上。这样就相当于你在浏览目标网站了。因此代理经常被叫做“梯子”或者“桥”。

**代理服务器的不足：**如果你希望达成匿名浏览网站之外的目的，代理服务器或许并不能帮你做到这点。长期使用代理服务器，你会发现它会变慢而且速度并不稳定。而如果你不只是匿名希望浏览几个网站，而是希望匿名访问大量网站和网络应用，代理服务器的弊端就会很明显。

> ### VPN简介

表面上，VPN和代理服务器是很接近的。在VPN服务下，你传输的信息会先经过VPN服务器，然后再抵达目的地，反过来的接收过程也是一样。而VPN和代理的主要区别就在于你向服务器发送数据的这个环节。 使用VPN，你必须先安装VPN软件（Windows 10虽然自带，但也是一个软件）。

**在开启VPN软件后，软件的主要职责就是加密你的数据并传递给VPN服务器，这样你传输的数据对截获者来说就是不可读的。这个技术叫做“隧道”，是一个很形象的词语。**



## listen backlog

**在做TCP 服务器时都会先有一步将绑定的IP 及端口进行监听的操作，在监听之后客户端就可以进行连接了。一但有客户进行连接内核会将它们放到另外一个接收队列中，这个队列中的连接将会由accept 来取走。如果没有来取走，或者取的速度慢于连接的速度那么这个队列就会满。一但这个队列满了之后那么客户端就无法连接到这个服务器上面了。而这个队列的大小就是由listen 中的blcklog 参数经过一定的算法得到的。**

**服务器监听时，在每次处理一个客户端的连接时是需要一定时间的，这个时间非常的短(也许只有1ms 或者还不到)，但这个时间还是存在的。而这个backlog 存在的意义就是：在这段时间里面除了第一个连接请求是正在进行处理以外，其他的连接请求都在请求队列中等待，而如果超过了队列的最大等待个数时，其他的请求将被忽略或者将不会被处理。**

**这个backlog 的值就是影响这个队列的大小的。但是这个backlog 值的大小并非直接等于队列的个数，队列的实际大小根据操作系统的不同而不同。也许有的是这个值，有的是2 \* backlog + 1 ，或者其他公式等等。**

当瞬间有大量client端连接尝试向server建立，server端的listen backlog队列满，server accept不及时((即便服务端不accept，那么在backlog数量范畴里面，客户端的connect都会是成功的，因为new conn已经加入到server side的listen queue中了，accept只是从queue中取出一个conn而 已)，这将导致client端Dial阻塞。
**“connectex: No connection could be made because the target machine actively refused it. ”**，和服务器没开启或者端口没监听的结果是一样的









